{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3085ec43-34bb-4afb-9515-517e0489db3e",
   "metadata": {},
   "source": [
    "## Классические алгоритмы без ансамблирования\n",
    "В этом ноутбуке вам нужно обучить модели на датасете классификации из предыдущего ноутбука и сравнить результаты. Вам будет предоставлен baseline, на основе которого вы будете доделывать предсказывающие модели. Оценка лабы будет зависеть от ROC-AUC на тестовых данных по следующим критериям:\n",
    "\\\n",
    "AUC - на тестовых данных\n",
    "- $AUC \\leq 0.75$ - 0 баллов\n",
    "- $0.75 < AUC \\leq 0.76$ - 2 балла\n",
    "- $0.76 < AUC \\leq 0.77$ - 4 балла\n",
    "- $0.77 < AUC \\leq 0.78$ - 6 баллов\n",
    "- $0.78 < AUC \\leq 0.79$ - 8 баллов\n",
    "- $AUC > 0.79$ - 10 баллов\n",
    "\n",
    "\\\n",
    "В этой работе запрещено использовать ансамбли моделей (лес, бустинги и т.д.)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07e3a2-480a-4350-868e-02679ff2aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ad31b-5c83-4366-819a-34dad4edecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('german.csv', sep=';')\n",
    "print(data.head())\n",
    "\n",
    "X = data.iloc[:, 1:].to_numpy()\n",
    "y = data.iloc[:, 0].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93737ec-e5eb-4d72-8beb-5dba4d4c581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_train, bins=2, edgecolor='k')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccf0690-1d07-4026-85f2-674c5688d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_model = best_lr\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "decision_tree_model = best_dt\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "knn_model = best_knn\n",
    "knn_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebd8b0-3f81-4365-9f84-44bf50bbcbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_logistic = logistic_regression_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_decision_tree = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test)\n",
    "y_pred_decision_tree = decision_tree_model.predict(X_test)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "roc_auc_logistic = roc_auc_score(y_test, y_prob_logistic)\n",
    "roc_auc_decision_tree = roc_auc_score(y_test, y_prob_decision_tree)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
    "\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "precision_decision_tree = precision_score(y_test, y_pred_decision_tree)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "recall_decision_tree = recall_score(y_test, y_pred_decision_tree)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f'Accuracy of Logistic Regression: {accuracy_logistic}')\n",
    "print(f'Accuracy of Decision Tree: {accuracy_decision_tree}')\n",
    "print(f'Accuracy of K-Nearest Neighbors: {accuracy_knn}')\n",
    "\n",
    "print(f'ROC AUC of Logistic Regression: {roc_auc_logistic}')\n",
    "print(f'ROC AUC of Decision Tree: {roc_auc_decision_tree}')\n",
    "print(f'ROC AUC of K-Nearest Neighbors: {roc_auc_knn}')\n",
    "\n",
    "print(f'Precision of Logistic Regression: {precision_logistic}')\n",
    "print(f'Precision of Decision Tree: {precision_decision_tree}')\n",
    "print(f'Precision of K-Nearest Neighbors: {precision_knn}')\n",
    "\n",
    "print(f'Recall of Logistic Regression: {recall_logistic}')\n",
    "print(f'Recall of Decision Tree: {recall_decision_tree}')\n",
    "print(f'Recall of K-Nearest Neighbors: {recall_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d6eb00-77fd-40dc-a3c5-35c1fe0200c0",
   "metadata": {},
   "source": [
    "## Экспериментируйте\n",
    "Для получения лучшего качества придется поэкспериментировать. Подсказка: попробуйте оптимизировать гиперпараметры модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c8c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('german.csv', sep=';')\n",
    "print(data.head())\n",
    "\n",
    "X = data.iloc[:, 1:].to_numpy()\n",
    "y = data.iloc[:, 0].to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "plt.hist(y_train, bins=2, edgecolor='k')\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('Class (0: Non-Creditworthy, 1: Creditworthy)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Classes in Training Data')\n",
    "plt.show()\n",
    "\n",
    "# Нормализация данных для KNN и Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Оптимизация гиперпараметров для Logistic Regression\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "grid_lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=1000), \n",
    "                      param_grid_lr, cv=5, scoring='roc_auc')\n",
    "grid_lr.fit(X_train_scaled, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "\n",
    "# Оптимизация гиперпараметров для Decision Tree\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), \n",
    "                      param_grid_dt, cv=5, scoring='roc_auc')\n",
    "grid_dt.fit(X_train, y_train)\n",
    "best_dt = grid_dt.best_estimator_\n",
    "\n",
    "# Оптимизация гиперпараметров для KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), \n",
    "                       param_grid_knn, cv=5, scoring='roc_auc')\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "best_knn = grid_knn.best_estimator_\n",
    "\n",
    "print(\"Лучшие параметры Logistic Regression:\", grid_lr.best_params_)\n",
    "print(\"Лучшие параметры Decision Tree:\", grid_dt.best_params_)\n",
    "print(\"Лучшие параметры KNN:\", grid_knn.best_params_)\n",
    "\n",
    "logistic_regression_model = best_lr\n",
    "logistic_regression_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "decision_tree_model = best_dt\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "knn_model = best_knn\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_prob_logistic = logistic_regression_model.predict_proba(X_test_scaled)[:, 1]\n",
    "y_prob_decision_tree = decision_tree_model.predict_proba(X_test)[:, 1]\n",
    "y_prob_knn = knn_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "y_pred_logistic = logistic_regression_model.predict(X_test_scaled)\n",
    "y_pred_decision_tree = decision_tree_model.predict(X_test)\n",
    "y_pred_knn = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Метрики\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "accuracy_decision_tree = accuracy_score(y_test, y_pred_decision_tree)\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "roc_auc_logistic = roc_auc_score(y_test, y_prob_logistic)\n",
    "roc_auc_decision_tree = roc_auc_score(y_test, y_prob_decision_tree)\n",
    "roc_auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
    "\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "precision_decision_tree = precision_score(y_test, y_pred_decision_tree)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "recall_decision_tree = recall_score(y_test, y_pred_decision_tree)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f'Accuracy of Logistic Regression: {accuracy_logistic}')\n",
    "print(f'Accuracy of Decision Tree: {accuracy_decision_tree}')\n",
    "print(f'Accuracy of K-Nearest Neighbors: {accuracy_knn}')\n",
    "\n",
    "print(f'ROC AUC of Logistic Regression: {roc_auc_logistic}')\n",
    "print(f'ROC AUC of Decision Tree: {roc_auc_decision_tree}')\n",
    "print(f'ROC AUC of K-Nearest Neighbors: {roc_auc_knn}')\n",
    "\n",
    "print(f'Precision of Logistic Regression: {precision_logistic}')\n",
    "print(f'Precision of Decision Tree: {precision_decision_tree}')\n",
    "print(f'Precision of K-Nearest Neighbors: {precision_knn}')\n",
    "\n",
    "print(f'Recall of Logistic Regression: {recall_logistic}')\n",
    "print(f'Recall of Decision Tree: {recall_decision_tree}')\n",
    "print(f'Recall of K-Nearest Neighbors: {recall_knn}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
